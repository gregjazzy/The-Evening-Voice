/**
 * API Route - Chat avec l'IA-Amie (nom personnalisable)
 * Utilise le syst√®me des 5 Cl√©s Magiques (images) + 5 Questions Magiques (√©criture)
 * + Syst√®me de guidage visuel (highlights)
 */

import { NextRequest, NextResponse } from 'next/server'
import { generateLunaResponse, type ChatMessage, type LunaContext } from '@/lib/ai/gemini'
import type { PromptingProgress, StoryStructure, WritingPromptingProgress } from '@/lib/ai/prompting-pedagogy'
import { parseHighlightCommands, generateInterfaceKnowledge, type HighlightConfig } from '@/store/useHighlightStore'
import { getApiKeyForRequest } from '@/lib/config/server-config'
import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from '@google/generative-ai'

// Mod√©ration du contenu via Gemini
async function isContentAppropriate(text: string, apiKey: string): Promise<boolean> {
  if (!text || text.length < 5) return true
  
  try {
    const genAI = new GoogleGenerativeAI(apiKey)
    const model = genAI.getGenerativeModel({ 
      model: 'gemini-2.0-flash',
      safetySettings: [
        { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_NONE },
        { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_NONE },
        { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_NONE },
        { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_NONE },
      ],
    })

    const prompt = `Tu es un mod√©rateur de contenu pour une application destin√©e aux enfants de 4 √† 10 ans.
    
Un enfant a √©crit ce message : "${text}"

Ce message est-il appropri√© pour un enfant ? R√©ponds UNIQUEMENT par "OUI" ou "NON".

Crit√®res pour r√©pondre "NON" :
- Gros mots ou insultes (m√™me d√©guis√©s)
- Contenu sexuel ou r√©f√©rences au sexe
- Violence graphique
- Th√®mes adultes inappropri√©s

R√©ponds "OUI" si c'est une question innocente sur l'√©criture d'histoire.`

    const result = await model.generateContent(prompt)
    const response = result.response.text().trim().toUpperCase()
    return response.includes('OUI')
  } catch (error) {
    console.error('Erreur mod√©ration:', error)
    return true // Fail-open
  }
}

// R√©ponses de redirection pour contenu inappropri√©
const REDIRECT_RESPONSES = {
  fr: "Hmm, je pr√©f√®re qu'on parle d'autre chose ! üòä Qu'est-ce que tu aimerais raconter comme histoire ? Un aventurier courageux ? Une princesse magique ? Un animal rigolo ?",
  en: "Hmm, let's talk about something else! üòä What kind of story would you like to tell? A brave adventurer? A magical princess? A funny animal?",
  ru: "–•–º, –¥–∞–≤–∞–π –ø–æ–≥–æ–≤–æ—Ä–∏–º –æ —á—ë–º-—Ç–æ –¥—Ä—É–≥–æ–º! üòä –ö–∞–∫—É—é –∏—Å—Ç–æ—Ä–∏—é —Ç—ã —Ö–æ—á–µ—à—å —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å? –û —Ö—Ä–∞–±—Ä–æ–º –ø—Ä–∏–∫–ª—é—á–µ–Ω—Ü–µ? –û –≤–æ–ª—à–µ–±–Ω–æ–π –ø—Ä–∏–Ω—Ü–µ—Å—Å–µ? –û –∑–∞–±–∞–≤–Ω–æ–º –∂–∏–≤–æ—Ç–Ω–æ–º?"
}

interface ChatRequestBody {
  message: string
  context?: 'diary' | 'book' | 'studio' | 'montage' | 'general'
  currentMode?: string // Mode actuel de l'interface (pour le guidage visuel)
  locale?: 'fr' | 'en' | 'ru'
  aiName?: string // Nom personnalis√© de l'IA
  userName?: string // Pr√©nom de l'enfant
  chatHistory?: ChatMessage[]
  emotionalContext?: string[]
  promptingProgress?: PromptingProgress
  writingProgress?: WritingPromptingProgress
  storyStructure?: StoryStructure
  storyStep?: number
  // Contexte sp√©cifique au Studio
  studioContext?: {
    type: 'image' | 'video'
    currentStep?: string
    level?: number
    // √âtat du kit de cr√©ation
    kit?: {
      subject?: string
      subjectDetails?: string
      style?: string | null
      ambiance?: string | null
      light?: string | null
    } | null
    // √âl√©ments manquants d√©tect√©s
    missingElements?: string[]
    // √âtapes compl√©t√©es
    completedSteps?: string[]
  }
}

interface ChatResponse {
  text: string
  highlights?: HighlightConfig[]
}

export async function POST(request: NextRequest) {
  try {
    const body: ChatRequestBody = await request.json()
    const { 
      message, 
      context = 'general',
      currentMode,
      locale = 'fr',
      aiName,
      userName,
      chatHistory = [], 
      emotionalContext = [],
      promptingProgress,
      writingProgress,
      storyStructure,
      storyStep,
      studioContext
    } = body

    if (!message) {
      return NextResponse.json(
        { error: 'Message requis' },
        { status: 400 }
      )
    }

    // R√©cup√©rer la cl√© API pour la mod√©ration
    const apiKey = await getApiKeyForRequest('gemini')
    
    // Mod√©rer le contenu du message de l'enfant
    if (apiKey) {
      const isAppropriate = await isContentAppropriate(message, apiKey)
      if (!isAppropriate) {
        console.log(`üõ°Ô∏è Contenu bloqu√© dans chat: "${message.substring(0, 50)}..."`)
        return NextResponse.json({
          text: REDIRECT_RESPONSES[locale] || REDIRECT_RESPONSES.fr,
          highlights: undefined,
        })
      }
    }

    // G√©n√©rer le contexte de l'interface pour le guidage visuel
    const interfaceMode = currentMode || context || 'general'
    const interfaceKnowledge = generateInterfaceKnowledge(interfaceMode)

    // Construire le contexte de l'IA-Amie
    const aiContext: LunaContext = {
      mode: context,
      locale,
      aiName, // Nom personnalis√© transmis au prompt
      userName, // Pr√©nom de l'enfant pour personnaliser les r√©ponses
      apiKey: apiKey || undefined, // Cl√© API dynamique
      promptingProgress,
      writingProgress,
      storyStructure,
      storyStep,
      emotionalContext,
      studioType: studioContext?.type, // Type de cr√©ation studio (image/video)
      // Nouveau : contexte enrichi pour le Studio
      studioKit: studioContext?.kit,
      studioMissingElements: studioContext?.missingElements,
      studioLevel: studioContext?.level,
      studioConsecutiveStruggles: studioContext?.consecutiveStruggles, // Blocages r√©p√©t√©s
      // Nouveau : connaissance de l'interface pour le guidage visuel
      interfaceKnowledge,
    }

    // G√©n√©rer la r√©ponse de l'IA-Amie
    const rawResponse = await generateLunaResponse(
      message,
      aiContext,
      chatHistory
    )

    // Parser les commandes de highlight dans la r√©ponse
    const { cleanText, highlights } = parseHighlightCommands(rawResponse.text)

    // Retourner la r√©ponse nettoy√©e avec les highlights
    const response: ChatResponse = {
      text: cleanText,
      highlights: highlights.length > 0 ? highlights : undefined,
    }

    return NextResponse.json(response)
  } catch (error) {
    console.error('Erreur API chat:', error)
    return NextResponse.json(
      { error: 'Erreur lors de la g√©n√©ration de la r√©ponse' },
      { status: 500 }
    )
  }
}
